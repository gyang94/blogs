<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Tiering Service Deep Dive | GYang's Blogs</title>
    <meta name="description" content="顺其自然的学习小屋">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/blogs/assets/style.B0DM1zzG.css" as="style">
    <link rel="preload stylesheet" href="/blogs/vp-icons.css" as="style">
    
    <script type="module" src="/blogs/assets/app.Yg8RU0lp.js"></script>
    <link rel="preload" href="/blogs/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/blogs/assets/chunks/theme.4_oNNiT9.js">
    <link rel="modulepreload" href="/blogs/assets/chunks/framework.Bk39dawk.js">
    <link rel="modulepreload" href="/blogs/assets/chunks/tiering-committer.DtrepwyP.js">
    <link rel="modulepreload" href="/blogs/assets/notes_fluss_03-tiering-service-deep-dive.md.Db8wRR2L.lean.js">
    <link rel="icon" href="/blog.svg">
    <script src="https://cloud.umami.is/script.js" data-website-id="a389c094-c38f-4892-a805-600abb846e29"></script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-a4cba12c><!--[--><!--]--><!--[--><span tabindex="-1" data-v-88a8cb41></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-88a8cb41>Skip to content</a><!--]--><!----><header class="VPNav" data-v-a4cba12c data-v-aac6efe0><div class="VPNavBar" data-v-aac6efe0 data-v-3884d968><div class="wrapper" data-v-3884d968><div class="container" data-v-3884d968><div class="title" data-v-3884d968><div class="VPNavBarTitle has-sidebar" data-v-3884d968 data-v-58eee3d4><a class="title" href="/blogs/" data-v-58eee3d4><!--[--><!--]--><!--[--><img class="VPImage logo" src="/blogs/data-lake.png" alt data-v-7018b892><!--]--><span data-v-58eee3d4>GYang&#39;s Blogs</span><!--[--><!--]--></a></div></div><div class="content" data-v-3884d968><div class="content-body" data-v-3884d968><!--[--><!--]--><div class="VPNavBarSearch search" data-v-3884d968><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-3884d968 data-v-9d15defd><span id="main-nav-aria-label" class="visually-hidden" data-v-9d15defd> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blogs/" tabindex="0" data-v-9d15defd data-v-79e74c62><!--[--><span data-v-79e74c62>Home</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-9d15defd data-v-1cd8686e><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-1cd8686e><span class="text" data-v-1cd8686e><!----><span data-v-1cd8686e>学习笔记</span><span class="vpi-chevron-down text-icon" data-v-1cd8686e></span></span></button><div class="menu" data-v-1cd8686e><div class="VPMenu" data-v-1cd8686e data-v-615fc6ac><div class="items" data-v-615fc6ac><!--[--><!--[--><div class="VPMenuLink" data-v-615fc6ac data-v-f3c5cc36><a class="VPLink link" href="/blogs/notes/fluss/fluss-category.html" data-v-f3c5cc36><!--[--><span data-v-f3c5cc36>Fluss</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-615fc6ac data-v-f3c5cc36><a class="VPLink link" href="/blogs/notes/flink/flink-category.html" data-v-f3c5cc36><!--[--><span data-v-f3c5cc36>Flink</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-615fc6ac data-v-f3c5cc36><a class="VPLink link" href="/blogs/notes/kafka/kafka-category.html" data-v-f3c5cc36><!--[--><span data-v-f3c5cc36>Kafka</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-615fc6ac data-v-f3c5cc36><a class="VPLink link" href="/blogs/notes/iceberg/iceberg-category.html" data-v-f3c5cc36><!--[--><span data-v-f3c5cc36>Iceberg</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-615fc6ac data-v-f3c5cc36><a class="VPLink link" href="/blogs/notes/paimon/paimon-category.html" data-v-f3c5cc36><!--[--><span data-v-f3c5cc36>Paimon</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-3884d968 data-v-25bc2676><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-25bc2676 data-v-ede464e2 data-v-019d2d21><span class="check" data-v-019d2d21><span class="icon" data-v-019d2d21><!--[--><span class="vpi-sun sun" data-v-ede464e2></span><span class="vpi-moon moon" data-v-ede464e2></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-3884d968 data-v-e7a2a48b data-v-5a009cac><!--[--><a class="VPSocialLink no-icon" href="https://github.com/gyang94" aria-label="github" target="_blank" rel="noopener" data-v-5a009cac data-v-99001c8a><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-3884d968 data-v-607ef21f data-v-1cd8686e><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-1cd8686e><span class="vpi-more-horizontal icon" data-v-1cd8686e></span></button><div class="menu" data-v-1cd8686e><div class="VPMenu" data-v-1cd8686e data-v-615fc6ac><!----><!--[--><!--[--><!----><div class="group" data-v-607ef21f><div class="item appearance" data-v-607ef21f><p class="label" data-v-607ef21f>Appearance</p><div class="appearance-action" data-v-607ef21f><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-607ef21f data-v-ede464e2 data-v-019d2d21><span class="check" data-v-019d2d21><span class="icon" data-v-019d2d21><!--[--><span class="vpi-sun sun" data-v-ede464e2></span><span class="vpi-moon moon" data-v-ede464e2></span><!--]--></span></span></button></div></div></div><div class="group" data-v-607ef21f><div class="item social-links" data-v-607ef21f><div class="VPSocialLinks social-links-list" data-v-607ef21f data-v-5a009cac><!--[--><a class="VPSocialLink no-icon" href="https://github.com/gyang94" aria-label="github" target="_blank" rel="noopener" data-v-5a009cac data-v-99001c8a><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-3884d968 data-v-215e07c1><span class="container" data-v-215e07c1><span class="top" data-v-215e07c1></span><span class="middle" data-v-215e07c1></span><span class="bottom" data-v-215e07c1></span></span></button></div></div></div></div><div class="divider" data-v-3884d968><div class="divider-line" data-v-3884d968></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-a4cba12c data-v-e7a8c418><div class="container" data-v-e7a8c418><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-e7a8c418><span class="vpi-align-left menu-icon" data-v-e7a8c418></span><span class="menu-text" data-v-e7a8c418>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-e7a8c418 data-v-8fa4cf31><button data-v-8fa4cf31>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-a4cba12c data-v-c6614c00><div class="curtain" data-v-c6614c00></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-c6614c00><span class="visually-hidden" id="sidebar-aria-label" data-v-c6614c00> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-b0829ed6><section class="VPSidebarItem level-0 collapsible collapsed is-link" data-v-b0829ed6 data-v-dafd2763><div class="item" tabindex="0" data-v-dafd2763><div class="indicator" data-v-dafd2763></div><a class="VPLink link link" href="/blogs/notes/fluss/fluss-category.html" data-v-dafd2763><!--[--><h2 class="text" data-v-dafd2763>Fluss学习笔记</h2><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-dafd2763><span class="vpi-chevron-right caret-icon" data-v-dafd2763></span></div></div><div class="items" data-v-dafd2763><!--[--><div class="VPSidebarItem level-1 is-link" data-v-dafd2763 data-v-dafd2763><div class="item" data-v-dafd2763><div class="indicator" data-v-dafd2763></div><a class="VPLink link link" href="/blogs/notes/fluss/01-development-env-setup.html" data-v-dafd2763><!--[--><p class="text" data-v-dafd2763>01-搭建Fluss本地开发环境</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-dafd2763 data-v-dafd2763><div class="item" data-v-dafd2763><div class="indicator" data-v-dafd2763></div><a class="VPLink link link" href="/blogs/notes/fluss/02-fluss-catalog.html" data-v-dafd2763><!--[--><p class="text" data-v-dafd2763>02-Fluss Catalog</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-a4cba12c data-v-de90f256><div class="VPDoc has-sidebar has-aside" data-v-de90f256 data-v-fe0b286c><!--[--><!--]--><div class="container" data-v-fe0b286c><div class="aside" data-v-fe0b286c><div class="aside-curtain" data-v-fe0b286c></div><div class="aside-container" data-v-fe0b286c><div class="aside-content" data-v-fe0b286c><div class="VPDocAside" data-v-fe0b286c data-v-8d42c92f><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-8d42c92f data-v-ad9d4535><div class="content" data-v-ad9d4535><div class="outline-marker" data-v-ad9d4535></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-ad9d4535>On this page</div><ul class="VPDocOutlineItem root" data-v-ad9d4535 data-v-c561ae38><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-8d42c92f></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-fe0b286c><div class="content-container" data-v-fe0b286c><!--[--><!--]--><main class="main" data-v-fe0b286c><div style="position:relative;" class="vp-doc _blogs_notes_fluss_03-tiering-service-deep-dive" data-v-fe0b286c><div><h1 id="tiering-service-deep-dive" tabindex="-1">Tiering Service Deep Dive <a class="header-anchor" href="#tiering-service-deep-dive" aria-label="Permalink to &quot;Tiering Service Deep Dive&quot;">​</a></h1><h2 id="background" tabindex="-1">Background <a class="header-anchor" href="#background" aria-label="Permalink to &quot;Background&quot;">​</a></h2><p><img src="/blogs/assets/background.D9l9lEfs.png" alt=""></p><p>At the core of Fluss’s Lakehouse architecture sits the Tiering Service—a smart, policy-driven data pipeline that seamlessly bridges your real-time Fluss cluster and your cost-efficient lakehouse storage. It continuously ingests fresh events from the fluss cluster, automatically migrating older or less-frequently accessed data into colder storage tiers without interrupting ongoing queries. By balancing hot, warm, and cold storage according to configurable rules, the Tiering Service ensures that recent data remains instantly queryable while historical records are archived economically. In this deep dive, we’ll explore how Fluss’s Tiering Service orchestrates data movement, preserves consistency, and empowers you to scale analytics workloads with both performance and cost in mind.</p><h2 id="flink-tiering-service" tabindex="-1">Flink Tiering Service <a class="header-anchor" href="#flink-tiering-service" aria-label="Permalink to &quot;Flink Tiering Service&quot;">​</a></h2><p>Fluss tiering service is an flink job, which keeps moving data from fluss cluster to data lake. The execution plan is quite straight forward. It has a three operators: a source, a committer and a empty sink writer.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span> Source: TieringSource -&gt; TieringCommitter -&gt; Sink: Writer</span></span></code></pre></div><ul><li><strong>TieringSource</strong>: Reads records from the Fluss tiering table and writes them to the data lake.</li><li><strong>TieringCommitter</strong>: Commits each sync batch by advancing offsets in both the lakehouse and the Fluss cluster.</li><li><strong>No-Op Sink</strong>: A dummy sink that performs no action.</li></ul><p>In the sections that follow, we’ll dive into the TieringSource and TieringCommitter to see exactly how they orchestrate seamless data movement between real-time and historical storage.</p><h2 id="tieringsource" tabindex="-1">TieringSource <a class="header-anchor" href="#tieringsource" aria-label="Permalink to &quot;TieringSource&quot;">​</a></h2><p><img src="/blogs/assets/tiering-source.CcffHvhe.png" alt=""></p><p>The <strong>TieringSource</strong> operator reads records from the Fluss tiering table and writes them into your data lake. Built on Flink’s Source V2 API (FLIP-27), it breaks down into two core components: the <strong>TieringSourceEnumerator</strong> and the <strong>TieringSourceReader</strong>. The high-level workflow is:</p><ol><li><strong>Enumerator</strong> queries the CoordinatorService for current tiering table metadata.</li><li>Once it receives the table information, the Enumerator generates “splits” (data partitions) and assigns them to the Reader.</li><li><strong>Reader</strong> fetches the actual data for each split.</li><li>The Reader then writes those records into the data lake.</li></ol><p>In the following sections, we’ll explore how the TieringSourceEnumerator and TieringSourceReader work under the hood to deliver reliable, scalable ingestion from Fluss into your lakehouse.</p><h3 id="tieringsourceenumerator" tabindex="-1">TieringSourceEnumerator <a class="header-anchor" href="#tieringsourceenumerator" aria-label="Permalink to &quot;TieringSourceEnumerator&quot;">​</a></h3><p><img src="/blogs/assets/tiering-source-enumerator.DO9TQIWH.png" alt=""></p><p>The <strong>TieringSourceEnumerator</strong> orchestrates split creation and assignment in five key steps:</p><ol><li><strong>Heartbeat Request</strong>: Uses an RPC client to send a <code>lakeTieringHeartbeatRequest</code> to the Fluss server.</li><li><strong>Heartbeat Response</strong>: Receives a <code>lakeTieringHeartbeatResponse</code> containing tiering table metadata and sync statuses for completed, failed, and in-progress tables.</li><li><strong>Lake Tiering Info</strong>: Forwards the returned <code>lakeTieringInfo</code> to the <code>TieringSplitGenerator</code>.</li><li><strong>Split Generation</strong>: The <code>TieringSplitGenerator</code> produces a set of <code>TieringSplits</code>—each representing a data partition to process.</li><li><strong>Split Assignment</strong>: Assigns those <code>TieringSplits</code> to <code>TieringSourceReader</code> instances for downstream ingestion into the data lake.</li></ol><h4 id="rpcclient" tabindex="-1">RpcClient <a class="header-anchor" href="#rpcclient" aria-label="Permalink to &quot;RpcClient&quot;">​</a></h4><p>The <code>RpcClient</code> inside the <code>TieringSourceEnumerator</code> handles all RPC communication with the Fluss CoordinatorService. Its responsibilities include:</p><ul><li><strong>Sending Heartbeats</strong>: It constructs and sends a <code>LakeTieringHeartbeatRequest</code>, which carries three lists of tables—<code>tiering_tables</code> (in-progress), <code>finished_tables</code>, and <code>failed_tables</code>—along with an optional <code>request_table</code> flag to request new tiering work.</li><li><strong>Receiving Responses</strong>: It awaits a <code>LakeTieringHeartbeatResponse</code> that contains: <ul><li><code>coordinator_epoch</code>: the current epoch of the coordinator.</li><li><code>tiering_table</code> (optional): a <code>PbLakeTieringTableInfo</code> message (with <code>table_id</code>, <code>table_path</code>, and <code>tiering_epoch</code>) describing the next table to tier.</li><li><code>tiering_table_resp</code>, <code>finished_table_resp</code>, and <code>failed_table_resp</code>: lists of heartbeat responses reflecting the status of each table.</li></ul></li><li><strong>Forwarding Metadata</strong>: It parses the returned <code>PbLakeTieringTableInfo</code> and the sync-status responses, then forwards the assembled <code>lakeTieringInfo</code> to the <code>TieringSplitGenerator</code> for split creation.</li></ul><h4 id="tieringsplitgenerator" tabindex="-1">TieringSplitGenerator <a class="header-anchor" href="#tieringsplitgenerator" aria-label="Permalink to &quot;TieringSplitGenerator&quot;">​</a></h4><p><img src="/blogs/assets/tiering-split-generator.B6xePnA2.png" alt=""></p><p>The <strong>TieringSplitGenerator</strong> calculates the precise data delta between your lakehouse and the Fluss cluster, then emits <code>TieringSplit</code> tasks for each segment that needs syncing. It uses a <code>FlussAdminClient</code> to fetch three core pieces of metadata:</p><ol><li><strong>Lake Snapshot</strong><ul><li>Invokes the lake metadata API to retrieve a <code>LakeSnapshot</code> object, which includes: <ul><li><code>snapshotId</code> (the latest committed snapshot in the data lake)</li><li><code>tableBucketsOffset</code> (a map from each <code>TableBucket</code> to its log offset in the lakehouse)</li></ul></li></ul></li><li><strong>Current Bucket Offsets</strong><ul><li>Queries the Fluss server for each bucket’s current log end offset, capturing the high-water mark of incoming streams.</li></ul></li><li><strong>KV Snapshots (for primary-keyed tables)</strong><ul><li>Retrieves a <code>KvSnapshots</code> record containing: <ul><li><code>tableId</code> and optional <code>partitionId</code></li><li><code>snapshotIds</code> (latest snapshot ID per bucket)</li><li><code>logOffsets</code> (the log position to resume reading after that snapshot)</li></ul></li></ul></li></ol><p>With the <code>LakeSnapshot</code>, the live bucket offsets, and (when applicable) the <code>KvSnapshots</code>, the generator computes which log segments exist in Fluss but aren’t yet committed to the lake. It then produces one <code>TieringSplit</code> per segment—each split precisely defines the bucket and offset range to ingest—enabling incremental, efficient synchronization between real-time and historical storage.</p><h4 id="tieringsplit" tabindex="-1">TieringSplit <a class="header-anchor" href="#tieringsplit" aria-label="Permalink to &quot;TieringSplit&quot;">​</a></h4><p>The <strong>TieringSplit</strong> abstraction defines exactly which slice of a table bucket needs to be synchronized. It captures three common fields:</p><ul><li><strong>tablePath</strong>: the full path to the target table.</li><li><strong>tableBucket</strong>: the specific bucket (shard) within that table.</li><li><strong>partitionName</strong> (optional): the partition key, if the table is partitioned.</li></ul><p>There are two concrete split types:</p><ol><li><strong>TieringLogSplit</strong> (for append-only “log” tables) <ul><li><strong>startingOffset</strong>: the last committed log offset in the lake.</li><li><strong>stoppingOffset</strong>: the current end offset in the live Fluss bucket.</li><li>This split defines a contiguous range of new log records to ingest.</li></ul></li><li><strong>TieringSnapshotSplit</strong> (for primary-keyed tables) <ul><li><strong>snapshotId</strong>: the identifier of the latest snapshot in Fluss.</li><li><strong>logOffsetOfSnapshot</strong>: the log offset at which that snapshot was taken.</li><li>This split lets the TieringSourceReader replay all CDC (change-data-capture) events since the snapshot, ensuring up-to-date state.</li></ul></li></ol><p>By breaking each table into these well-defined splits, the Tiering Service can incrementally, reliably, and in parallel sync exactly the data that’s missing from your data lake.</p><h3 id="tieringsourcereader" tabindex="-1">TieringSourceReader <a class="header-anchor" href="#tieringsourcereader" aria-label="Permalink to &quot;TieringSourceReader&quot;">​</a></h3><p><img src="/blogs/assets/tiering-source-reader.B2yr9cMN.png" alt=""></p><p>The <strong>TieringSourceReader</strong> pulls assigned splits from the enumerator, uses a <code>TieringSplitReader</code> to fetch the corresponding records from the Fluss server, and then writes them into the data lake. Its workflow breaks down as follows:</p><ol><li><p><strong>Split Selection</strong></p><p>The reader picks an assigned <code>TieringSplit</code> from its queue.</p></li><li><p><strong>Reader Dispatch</strong></p><p>Depending on the split type, it instantiates either:</p><ul><li><strong>LogScanner</strong> for <code>TieringLogSplit</code> (append-only tables)</li><li><strong>BoundedSplitReader</strong> for <code>TieringSnapshotSplit</code> (primary-keyed tables)</li></ul></li><li><p><strong>Data Fetch</strong></p><p>The chosen reader fetches the records defined by the split’s offset or snapshot boundaries from the Fluss server.</p></li><li><p><strong>Lake Writing</strong></p><p>Retrieved records are handed off to the lake writer, which persists them into the data lake.</p></li></ol><p>By cleanly separating split assignment, reader selection, data fetching, and lake writing, the TieringSourceReader ensures scalable, parallel ingestion of streaming and snapshot data into your lakehouse.</p><h4 id="lakewriter-laketieringfactory" tabindex="-1">LakeWriter &amp; LakeTieringFactory <a class="header-anchor" href="#lakewriter-laketieringfactory" aria-label="Permalink to &quot;LakeWriter &amp; LakeTieringFactory&quot;">​</a></h4><p>The LakeWriter is responsible for persisting Fluss records into your data lake, and it’s instantiated via a pluggable LakeTieringFactory. This interface defines how Fluss interacts with various lake formats (e.g., Paimon, Iceberg):</p><div class="language-java vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">public</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> interface</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> LakeTieringFactory</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	LakeWriter&lt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">WriteResult</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt; </span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">createLakeWriter</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(WriterInitContext </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">writerInitContext</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">);</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	SimpleVersionedSerializer&lt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">WriteResult</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt; </span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">getWriteResultSerializer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	LakeCommitter&lt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">WriteResult</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">CommitableT</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt; </span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">createLakeCommitter</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            CommitterInitContext </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">committerInitContext</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">);</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	SimpleVersionedSerializer&lt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">CommitableT</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt; </span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">getCommitableSerializer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><ul><li><strong>createLakeWriter(WriterInitContext)</strong>: builds a <code>LakeWriter</code> to convert Fluss rows into the target table format.</li><li><strong>getWriteResultSerializer()</strong>: supplies a serializer for the writer’s output.</li><li><strong>createLakeCommitter(CommitterInitContext)</strong>: constructs a <code>LakeCommitter</code> to finalize and atomically commit data files.</li><li><strong>getCommitableSerializer()</strong>: provides a serializer for committable tokens.```</li></ul><p>By default, Fluss includes a Paimon-backed tiering factory; Iceberg support is coming soon. Once the <code>TieringSourceReader</code> writes a batch of records through the <code>LakeWriter</code>, it emits the resulting write metadata downstream to the <strong>TieringCommitOperator</strong>, which then commits those changes both in the lakehouse and back to the Fluss cluster.</p><h4 id="stateless" tabindex="-1">Stateless <a class="header-anchor" href="#stateless" aria-label="Permalink to &quot;Stateless&quot;">​</a></h4><p>The <code>TieringSourceReader</code> is designed to be completely stateless—it does not checkpoint or store any <code>TieringSplit</code> information itself. Instead, every checkpoint simply returns an empty list, leaving all split-tracking to the <code>TieringSourceEnumerator</code>:</p><div class="language-java vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">@</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">Override</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">public</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> List</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">TieringSplit</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> snapshotState</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">long</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> checkpointId) {</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    // Stateless: no splits are held in reader state</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Collections.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">emptyList</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>By delegating split assignment entirely to the Enumerator, the reader remains lightweight and easily scalable, always fetching its next work unit afresh from the coordinator.</p><h2 id="tieringcommitter" tabindex="-1">TieringCommitter <a class="header-anchor" href="#tieringcommitter" aria-label="Permalink to &quot;TieringCommitter&quot;">​</a></h2><p><img src="/blogs/assets/tiering-committer.D8pdgUP4.png" alt=""></p><p>The <strong>TieringCommitter</strong> operator wraps up each sync cycle by taking the <code>WriteResult</code> outputs from the TieringSourceReader and committing them in two phases—first to the data lake, then back to Fluss—before emitting status events to the Flink coordinator. It leverages two components:</p><ul><li><strong>LakeCommitter</strong>: Provided by the pluggable <code>LakeTieringFactory</code>, this component atomically commits the written files into the lakehouse and returns the new snapshot ID.</li><li><strong>FlussTableLakeSnapshotCommitter</strong>: Using that snapshot ID, it updates the Fluss cluster’s tiering table status so that the Fluss server and lakehouse remain in sync.</li></ul><p>The end-to-end flow is:</p><ol><li><strong>Collect Write Results</strong> from the TieringSourceReader for the current checkpoint.</li><li><strong>Lake Commit</strong> via the <code>LakeCommitter</code>, which finalizes files and advances the lake snapshot.</li><li><strong>Fluss Update</strong> using the <code>FlussTableLakeSnapshotCommitter</code>, acknowledging success or failure back to the Fluss CoordinatorService.</li><li><strong>Event Emission</strong> of either <code>FinishedTieringEvent</code> (on success or completion) or <code>FailedTieringEvent</code> (on errors) to the Flink <code>OperatorCoordinator</code>.</li></ol><p>This TieringCommitter operator ensures exactly-once consistent synchronization between your real-time Fluss cluster and your analytical lakehouse.</p><h2 id="conclusion" tabindex="-1">Conclusion <a class="header-anchor" href="#conclusion" aria-label="Permalink to &quot;Conclusion&quot;">​</a></h2><p>In this deep dive, we dissected every layer of Fluss’s Tiering Service—starting with the TieringSource (Enumerator, RpcClient, and SplitGenerator), moving through split types and the stateless TieringSourceReader, and exploring the pluggable LakeWriter/LakeCommitter integration. We then saw how the TieringCommitter (with its LakeCommitter and FlussTableLakeSnapshotCommitter) ensures atomic, exactly-once commits across both your data lake and Fluss cluster. Together, these components deliver a robust pipeline that reliably syncs real-time streams and historical snapshots, giving you seamless, scalable consistency between live workloads and analytical storage.</p></div></div></main><footer class="VPDocFooter" data-v-fe0b286c data-v-9be8bc63><!--[--><!--]--><div class="edit-info" data-v-9be8bc63><!----><div class="last-updated" data-v-9be8bc63><p class="VPLastUpdated" data-v-9be8bc63 data-v-3f6de789>最后更新: <time datetime="2025-07-06T04:48:40.000Z" data-v-3f6de789></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-9be8bc63><span class="visually-hidden" id="doc-footer-aria-label" data-v-9be8bc63>Pager</span><div class="pager" data-v-9be8bc63><!----></div><div class="pager" data-v-9be8bc63><a class="VPLink link pager-link next" href="/blogs/notes/fluss/fluss-category.html" data-v-9be8bc63><!--[--><span class="desc" data-v-9be8bc63>Next page</span><span class="title" data-v-9be8bc63>Fluss学习笔记</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"eUi43j0R\",\"index.md\":\"XbXCu8A3\",\"markdown-examples.md\":\"Co7DY6ms\",\"material.md\":\"CmbYY8_L\",\"notes_flink_flink-category.md\":\"B0mQP8eA\",\"notes_flink_flink-connector-kafka.md\":\"D1vR-xOv\",\"notes_fluss_01-development-env-setup.md\":\"D7Hy2vPN\",\"notes_fluss_02-fluss-catalog.md\":\"o82xtdu0\",\"notes_fluss_03-tiering-service-deep-dive-zh.md\":\"CIV1IDFA\",\"notes_fluss_03-tiering-service-deep-dive.md\":\"Db8wRR2L\",\"notes_fluss_04-hands-on-fluss-lakehouse.md\":\"BXnC93xE\",\"notes_fluss_fluss-category.md\":\"N-4PbAcZ\",\"notes_iceberg_01-files.md\":\"BnN3XB3U\",\"notes_iceberg_02-features.md\":\"B5m2WqFC\",\"notes_iceberg_03-flink-integration.md\":\"CujVo6cw\",\"notes_iceberg_iceberg-category.md\":\"DA6zq2Kn\",\"notes_kafka_01-intro.md\":\"DnI_vQP9\",\"notes_kafka_02-kafka-cli.md\":\"BxOIRe79\",\"notes_kafka_kafka-category.md\":\"Bp40SlJQ\",\"notes_kafka_source-code_producer_producer-init.md\":\"NmAT3idi\",\"notes_kafka_source-code_producer_producer-metadata.md\":\"Dt4x5wnb\",\"notes_kafka_source-code_producer_producer-processing-flow.md\":\"B7PX4xUg\",\"notes_paimon_01-intro.md\":\"CvCjOcSc\",\"notes_paimon_02-lsm.md\":\"P5Wk98dq\",\"notes_paimon_03-paimon-table.md\":\"BYVcs8Za\",\"notes_paimon_paimon-category.md\":\"DP2QmbKP\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"GYang's Blogs\",\"description\":\"顺其自然的学习小屋\",\"base\":\"/blogs/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"logo\":\"/data-lake.png\",\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"学习笔记\",\"items\":[{\"text\":\"Fluss\",\"link\":\"/notes/fluss/fluss-category\"},{\"text\":\"Flink\",\"link\":\"/notes/flink/flink-category\"},{\"text\":\"Kafka\",\"link\":\"/notes/kafka/kafka-category\"},{\"text\":\"Iceberg\",\"link\":\"/notes/iceberg/iceberg-category\"},{\"text\":\"Paimon\",\"link\":\"/notes/paimon/paimon-category\"}]}],\"sidebar\":{\"/notes/fluss/\":[{\"text\":\"Fluss学习笔记\",\"link\":\"/notes/fluss/fluss-category\",\"collapsed\":true,\"items\":[{\"text\":\"01-搭建Fluss本地开发环境\",\"link\":\"/notes/fluss/01-development-env-setup\"},{\"text\":\"02-Fluss Catalog\",\"link\":\"/notes/fluss/02-fluss-catalog\"}]}],\"/notes/kafka/\":[{\"text\":\"Kafka学习笔记\",\"link\":\"/notes/kafka/kafka-category\",\"collapsed\":true,\"items\":[{\"text\":\"01-kafka简介\",\"link\":\"/notes/kafka/01-intro\"},{\"text\":\"02-kafka命令合集\",\"link\":\"/notes/kafka/02-kafka-cli\"},{\"text\":\"Kafka源码系列\",\"items\":[{\"text\":\"Producer\",\"collapsed\":true,\"items\":[{\"text\":\"KafkaProducer源码 - 初始化\",\"link\":\"/notes/kafka/source-code/producer/producer-init\"},{\"text\":\"KafkaProducer源码 - 核心流程\",\"link\":\"/notes/kafka/source-code/producer/producer-processing-flow\"},{\"text\":\"KafkaProducer源码 - 元数据更新\",\"link\":\"/notes/kafka/source-code/producer/producer-metadata\"}]},{\"text\":\"Consumer\",\"items\":[]}]}]}],\"/notes/flink/\":[{\"text\":\"Flink学习笔记\",\"link\":\"/notes/flink/flink-category\",\"collapsed\":true,\"items\":[{\"text\":\"Flink源码 - 从Kafka Connector看Source接口重构\",\"link\":\"/notes/flink/flink-connector-kafka\"}]}],\"/notes/iceberg/\":[{\"text\":\"Iceberg学习笔记\",\"link\":\"/notes/iceberg/iceberg-category\",\"collapsed\":true,\"items\":[{\"text\":\"Iceberg文件布局\",\"link\":\"/notes/iceberg/01-files\"},{\"text\":\"Iceberg核心特性\",\"link\":\"/notes/iceberg/02-features\"},{\"text\":\"Flink与Iceberg集成\",\"link\":\"/notes/iceberg/03-flink-integration\"}]}],\"/notes/paimon/\":[{\"text\":\"Paimon学习笔记\",\"link\":\"/notes/paimon/paimon-category\",\"collapsed\":true,\"items\":[{\"text\":\"Paimon介绍\",\"link\":\"/notes/paimon/01-intro\"},{\"text\":\"LSM Tree\",\"link\":\"/notes/paimon/02-lsm\"},{\"text\":\"主键表和Append Only表\",\"link\":\"/notes/paimon/03-paimon-table\"}]}]},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/gyang94\"}],\"lastUpdated\":{\"text\":\"最后更新\",\"formatOptions\":{\"dateStyle\":\"full\",\"timeStyle\":\"medium\",\"hourCycle\":\"h24\"}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>